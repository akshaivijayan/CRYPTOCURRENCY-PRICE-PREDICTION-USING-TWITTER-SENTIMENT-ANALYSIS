{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP5U1tsZ5HJ5"
      },
      "source": [
        "# BitCoin Price Prediction using Sentiment analysis on social media\n",
        "* Aaron Paul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xs-PzIaM5HKC"
      },
      "outputs": [],
      "source": [
        "import pyspark as spark\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql.functions import col,udf,monotonically_increasing_id,unix_timestamp,round,avg\n",
        "import re\n",
        "sc = spark.SparkContext()\n",
        "sql = spark.SQLContext(sc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_spkEpz5HKF"
      },
      "source": [
        "## Loading tweets dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5CM0ej1x5HKG"
      },
      "outputs": [],
      "source": [
        "TwDF=pd.read_csv('/content/tweetsfinal1.csv',error_bad_lines=False,engine = 'python',header = None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7xLaVtm5HKJ"
      },
      "source": [
        "## Loading Bitcoin prices dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qp74Yfb_5HKK"
      },
      "outputs": [],
      "source": [
        "BtcDF=pd.read_csv('/content/BitCoinPrice.csv',error_bad_lines=False,engine = 'python',header = None)\n",
        "FullDataTw=sql.createDataFrame(TwDF)\n",
        "FullDataBtc=sql.createDataFrame(BtcDF) #creating pandas df and then changing it to pyspark df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UfHF5S1x5HKL"
      },
      "outputs": [],
      "source": [
        "FullDataTw = FullDataTw.dropna() #getting rid of full empty rows\n",
        "#print(FullDataTw.count())\n",
        "#print(FullDataBtc.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0g6lywSF5HKM"
      },
      "outputs": [],
      "source": [
        "FullDataTw.select(monotonically_increasing_id().alias(\"rowId\"),\"*\")\n",
        "FullDataTw = FullDataTw.withColumnRenamed('0', 'DateTime') #setting column names of Twitter dataset\n",
        "FullDataTw = FullDataTw.withColumnRenamed('1', 'Tweet')\n",
        "FullDataBtc = FullDataBtc.withColumnRenamed('0', 'DateTime') #setting column names of Bitcoin price dataset\n",
        "FullDataBtc = FullDataBtc.withColumnRenamed('1', 'Price')\n",
        "FullDataBtc = FullDataBtc.filter(FullDataBtc.DateTime != 'Date') #to get rid of first row with the header"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I5D77Ye5HKN"
      },
      "source": [
        "## Pre-Processing Twitter dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jYuXjgYA5HKO"
      },
      "outputs": [],
      "source": [
        "Tw_samp = FullDataTw  #.limit(100) #taking sample of 100 rows and working on it otherwise remove the limit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "w3XkL7TF5HKP",
        "outputId": "9dc0d7f7-6035-4223-f60f-2162e4dd5188",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|            DateTime|               Tweet|       CleanedTweets|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|Thu Nov 09 17:43:...|RT @Forbes: The F...|The Failure of Se...|\n",
            "|Thu Nov 09 17:43:...|RT @mindstatex: L...|Lots of love from...|\n",
            "|Thu Nov 09 17:43:...|RT @FernandoHuama...|Warning Built in ...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import preprocessor as p #cleaning each tweet using tweet-preprocessor like removing hashtags,urls,emojis....\n",
        "def function_udf(input_str):\n",
        "    input_str = re.sub(r'RT', '', input_str)\n",
        "    p.set_options(p.OPT.URL, p.OPT.EMOJI,p.OPT.MENTION)\n",
        "    input_str = p.clean(input_str)\n",
        "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", input_str).split())\n",
        "func_udf = udf(function_udf, StringType())\n",
        "CleanDF = Tw_samp.withColumn('CleanedTweets', func_udf(Tw_samp['Tweet']))\n",
        "CleanDF.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0jUDYzn5HKQ"
      },
      "source": [
        "## Sentiment analysis using Vader packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UDgk1MVw5HKQ",
        "outputId": "378a3d34-3e92-4dab-feb5-1e9dcc18de70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+-----+-----+-----+-------+\n",
            "|            DateTime|               Tweet|       CleanedTweets|p_neg|p_neu|p_pos| p_comp|\n",
            "+--------------------+--------------------+--------------------+-----+-----+-----+-------+\n",
            "|Thu Nov 09 17:43:...|RT @Forbes: The F...|The Failure of Se...|0.342|0.658|  0.0|-0.6914|\n",
            "|Thu Nov 09 17:43:...|RT @mindstatex: L...|Lots of love from...|  0.0|0.577|0.423|  0.875|\n",
            "|Thu Nov 09 17:43:...|RT @FernandoHuama...|Warning Built in ...|0.138|0.862|  0.0|  -0.34|\n",
            "+--------------------+--------------------+--------------------+-----+-----+-----+-------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyser = SentimentIntensityAnalyzer()\n",
        "def senti_score_udf(sentence):\n",
        "    snt = analyser.polarity_scores(sentence)\n",
        "    return ([snt['neg'], snt['neu'], snt['pos'], snt['compound']])\n",
        "func_udf2 = udf(senti_score_udf, ArrayType(FloatType()))\n",
        "CleanDF = CleanDF.withColumn('p_neg', func_udf2(CleanDF['CleanedTweets'])[0])\n",
        "CleanDF = CleanDF.withColumn('p_neu', func_udf2(CleanDF['CleanedTweets'])[1])\n",
        "CleanDF = CleanDF.withColumn('p_pos', func_udf2(CleanDF['CleanedTweets'])[2])\n",
        "CleanDF = CleanDF.withColumn('p_comp', func_udf2(CleanDF['CleanedTweets'])[3])\n",
        "CleanDF.show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BH4t0nRh5HKR",
        "outputId": "0e5f6a00-e423-4029-b9c3-e4e17acf16a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+-----+-----+-----+-------+-------------------+-------------------+\n",
            "|            DateTime|               Tweet|       CleanedTweets|p_neg|p_neu|p_pos| p_comp|         DateTime_c|    DateTime_casted|\n",
            "+--------------------+--------------------+--------------------+-----+-----+-----+-------+-------------------+-------------------+\n",
            "|Thu Nov 09 17:43:...|RT @Forbes: The F...|The Failure of Se...|0.342|0.658|  0.0|-0.6914|2017-11-09 17:43:41|2017-11-09 17:43:41|\n",
            "|Thu Nov 09 17:43:...|RT @mindstatex: L...|Lots of love from...|  0.0|0.577|0.423|  0.875|2017-11-09 17:43:40|2017-11-09 17:43:40|\n",
            "|Thu Nov 09 17:43:...|RT @FernandoHuama...|Warning Built in ...|0.138|0.862|  0.0|  -0.34|2017-11-09 17:43:39|2017-11-09 17:43:39|\n",
            "+--------------------+--------------------+--------------------+-----+-----+-----+-------+-------------------+-------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def Tw_Time_format(stri):  #manipulating and casting the strings(DateTime) of tweets dataframe to timestamps\n",
        "    dic = {'Nov':'11','Oct':'10'}\n",
        "    ans = ''\n",
        "    ans += stri[-4:]+'-'+ dic[stri[4:7]]+'-'+stri[8:19]\n",
        "    return ans\n",
        "func_udf3 = udf(Tw_Time_format,StringType())\n",
        "CleanDF = CleanDF.withColumn('DateTime_c', func_udf3(CleanDF['DateTime']))\n",
        "CleanDF = CleanDF.withColumn(\"DateTime_casted\",CleanDF['DateTime_c'].cast(TimestampType()))\n",
        "CleanDF.show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BC5dA65_5HKS",
        "outputId": "85004bd8-156e-48b1-9075-f5b468d9f49c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+-----+-----+-----+-------+\n",
            "|          Date_Time|      Cleaned_Tweets|p_neg|p_neu|p_pos| p_comp|\n",
            "+-------------------+--------------------+-----+-----+-----+-------+\n",
            "|2017-11-09 17:43:41|The Failure of Se...|0.342|0.658|  0.0|-0.6914|\n",
            "|2017-11-09 17:43:40|Lots of love from...|  0.0|0.577|0.423|  0.875|\n",
            "|2017-11-09 17:43:39|Warning Built in ...|0.138|0.862|  0.0|  -0.34|\n",
            "|2017-11-09 17:43:39|Join our telegram...|  0.0|0.845|0.155|  0.296|\n",
            "|2017-11-09 17:43:39|DIGAF FLOAT 16M T...|  0.0|  1.0|  0.0|    0.0|\n",
            "+-------------------+--------------------+-----+-----+-----+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "FinalTw = CleanDF.selectExpr(\"DateTime_casted as Date_Time\", \"CleanedTweets as Cleaned_Tweets\", \"p_neg\",\"p_neu\",\"p_pos\",\"p_comp\")\n",
        "FinalTw.show(5) #selecting necessary columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8eNCBmr5HKS"
      },
      "source": [
        "## Pre-Processing Bitcoin dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5HOhobVH5HKT",
        "outputId": "e469dfee-54bd-47ee-9900-ec937348b146",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-------+------------------+\n",
            "|     DateTime|  Price|  Cleaned_BTC_Time|\n",
            "+-------------+-------+------------------+\n",
            "|10/30/17 0:00|6123.21|2017-10-30 0:00:00|\n",
            "|10/30/17 1:00|6131.35|2017-10-30 1:00:00|\n",
            "|10/30/17 2:00|6114.17|2017-10-30 2:00:00|\n",
            "|10/30/17 3:00|6153.11|2017-10-30 3:00:00|\n",
            "|10/30/17 4:00|6151.09|2017-10-30 4:00:00|\n",
            "+-------------+-------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "from dateutil import parser\n",
        "def Btc_Time_format(input_str): #manipulating and casting the strings(DateTime) of BTC dataframe to timestamps\n",
        "    input_str = re.sub(r'/17','', input_str)\n",
        "    input_str = '2017-'+ input_str\n",
        "    input_str = re.sub(r'/', '-', input_str)\n",
        "    input_str += ':00'\n",
        "    return input_str[:10]+\"\"+input_str[10:]\n",
        "func_udf = udf(Btc_Time_format, StringType())\n",
        "FullDataBtc = FullDataBtc.withColumn('Cleaned_BTC_Time', func_udf(FullDataBtc['DateTime']))\n",
        "FullDataBtc.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6tXEbI765HKT",
        "outputId": "fdf958dc-e61d-4b8a-daac-31628eddf5c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------+\n",
            "|          Date_Time|  Price|\n",
            "+-------------------+-------+\n",
            "|2017-10-30 00:00:00|6123.21|\n",
            "|2017-10-30 01:00:00|6131.35|\n",
            "|2017-10-30 02:00:00|6114.17|\n",
            "|2017-10-30 03:00:00|6153.11|\n",
            "|2017-10-30 04:00:00|6151.09|\n",
            "+-------------------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "CleandfBtc = FullDataBtc.withColumn(\"Cleaned_BTC_Time_New\",FullDataBtc['Cleaned_BTC_Time'].cast(TimestampType()))\n",
        "FinalBtc = CleandfBtc.selectExpr(\"Cleaned_BTC_Time_New as Date_Time\", \"Price\")\n",
        "FinalBtc = FinalBtc.withColumn(\"Price\",FinalBtc['Price'].cast(DoubleType()))\n",
        "FinalBtc.show(5)#In this cell, casting to timesstamp, changing col names and casting price type to double"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYrrRJQg5HKU"
      },
      "source": [
        "## Dataframes Look like this..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Tj16hrOo5HKU",
        "outputId": "1a47a812-bff2-4864-82e6-7a106c88c441",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date_Time: timestamp (nullable = true)\n",
            " |-- Cleaned_Tweets: string (nullable = true)\n",
            " |-- p_neg: float (nullable = true)\n",
            " |-- p_neu: float (nullable = true)\n",
            " |-- p_pos: float (nullable = true)\n",
            " |-- p_comp: float (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "FinalTw.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KXk1I1s35HKU",
        "outputId": "544a4639-0968-4de1-8a8f-dbe7ccb8e26f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date_Time: timestamp (nullable = true)\n",
            " |-- Price: double (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "672"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "FinalBtc.printSchema()\n",
        "FinalBtc.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd5IHGGF5HKV"
      },
      "source": [
        "## Truncating timestamps to hours and then grouping them by hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9uTjnTXH5HKV",
        "outputId": "ebd1ae3c-3943-47ef-f0ea-d9d8dda62fad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+-----+-----+-----+-------+\n",
            "|          Date_Time|      Cleaned_Tweets|p_neg|p_neu|p_pos| p_comp|\n",
            "+-------------------+--------------------+-----+-----+-----+-------+\n",
            "|2017-11-09 23:00:00|The Failure of Se...|0.342|0.658|  0.0|-0.6914|\n",
            "|2017-11-09 23:00:00|Lots of love from...|  0.0|0.577|0.423|  0.875|\n",
            "|2017-11-09 23:00:00|Warning Built in ...|0.138|0.862|  0.0|  -0.34|\n",
            "|2017-11-09 23:00:00|Join our telegram...|  0.0|0.845|0.155|  0.296|\n",
            "|2017-11-09 23:00:00|DIGAF FLOAT 16M T...|  0.0|  1.0|  0.0|    0.0|\n",
            "+-------------------+--------------------+-----+-----+-----+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dt_truncated = ((round(unix_timestamp(col('Date_Time')) / 3600) * 3600).cast('timestamp'))\n",
        "FinalTw = FinalTw.withColumn('dt_truncated', dt_truncated)\n",
        "FinalTw = FinalTw.selectExpr(\"dt_truncated as Date_Time\",\"Cleaned_Tweets\",\"p_neg\",\"p_neu\",\"p_pos\",\"p_comp\")\n",
        "UTC = ((unix_timestamp(col('Date_Time'))+ 5*60*60).cast('timestamp'))\n",
        "FinalTw = FinalTw.withColumn('UTC', UTC)\n",
        "FinalTw = FinalTw.selectExpr(\"UTC as Date_Time\",\"Cleaned_Tweets\",\"p_neg\",\"p_neu\",\"p_pos\",\"p_comp\")\n",
        "FinalTw.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lEHXNlAJ5HKW",
        "outputId": "702ea642-a3ac-4dcd-867d-7210a0c51a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f2dae8fce1cb>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mFinalTw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregisterTempTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"temp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#FinalTw_avg = sql.sql(\"SELECT Date_Time As DateTime,AVG(p_neg) as P_Neg,AVG(p_neu) as P_Neu,AVG(p_pos) as P_Pos,AVG(p_comp) as P_Comp FROM temp GROUP BY Date_Time\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mFinalTw_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFinalTw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Date_Time\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"polarity\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"subj\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"p_pos\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"p_neg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Date_Time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"polarity\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"subj\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"p_pos\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"p_neg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mFinalTw_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3034\u001b[0m         \u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3035\u001b[0m         \"\"\"\n\u001b[0;32m-> 3036\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3037\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `polarity` cannot be resolved. Did you mean one of the following? [`p_comp`, `p_neg`, `p_neu`, `p_pos`, `Date_Time`].;\n'Project [Date_Time#272, 'polarity, 'subj, p_pos#59, p_neg#46]\n+- Project [UTC#264 AS Date_Time#272, Cleaned_Tweets#167, p_neg#46, p_neu#52, p_pos#59, p_comp#67]\n   +- Project [Date_Time#257, Cleaned_Tweets#167, p_neg#46, p_neu#52, p_pos#59, p_comp#67, cast((unix_timestamp(Date_Time#257, yyyy-MM-dd HH:mm:ss, Some(Etc/UTC), false) + cast(18000 as bigint)) as timestamp) AS UTC#264]\n      +- Project [dt_truncated#249 AS Date_Time#257, Cleaned_Tweets#167, p_neg#46, p_neu#52, p_pos#59, p_comp#67]\n         +- Project [Date_Time#166, Cleaned_Tweets#167, p_neg#46, p_neu#52, p_pos#59, p_comp#67, cast((round((cast(unix_timestamp(Date_Time#166, yyyy-MM-dd HH:mm:ss, Some(Etc/UTC), false) as double) / cast(3600 as double)), 0) * cast(3600 as double)) as timestamp) AS dt_truncated#249]\n            +- Project [DateTime_casted#116 AS Date_Time#166, CleanedTweets#27 AS Cleaned_Tweets#167, p_neg#46, p_neu#52, p_pos#59, p_comp#67]\n               +- Project [DateTime#14, Tweet#17, CleanedTweets#27, p_neg#46, p_neu#52, p_pos#59, p_comp#67, DateTime_c#107, cast(DateTime_c#107 as timestamp) AS DateTime_casted#116]\n                  +- Project [DateTime#14, Tweet#17, CleanedTweets#27, p_neg#46, p_neu#52, p_pos#59, p_comp#67, Tw_Time_format(DateTime#14)#106 AS DateTime_c#107]\n                     +- Project [DateTime#14, Tweet#17, CleanedTweets#27, p_neg#46, p_neu#52, p_pos#59, senti_score_udf(CleanedTweets#27)#66[3] AS p_comp#67]\n                        +- Project [DateTime#14, Tweet#17, CleanedTweets#27, p_neg#46, p_neu#52, senti_score_udf(CleanedTweets#27)#58[2] AS p_pos#59]\n                           +- Project [DateTime#14, Tweet#17, CleanedTweets#27, p_neg#46, senti_score_udf(CleanedTweets#27)#51[1] AS p_neu#52]\n                              +- Project [DateTime#14, Tweet#17, CleanedTweets#27, senti_score_udf(CleanedTweets#27)#45[0] AS p_neg#46]\n                                 +- Project [DateTime#14, Tweet#17, function_udf(Tweet#17)#26 AS CleanedTweets#27]\n                                    +- Project [DateTime#14, 1#1 AS Tweet#17]\n                                       +- Project [0#0 AS DateTime#14, 1#1]\n                                          +- Filter atleastnnonnulls(2, 0#0, 1#1)\n                                             +- LogicalRDD [0#0, 1#1], false\n"
          ]
        }
      ],
      "source": [
        "FinalTw.registerTempTable(\"temp\")\n",
        "#FinalTw_avg = sql.sql(\"SELECT Date_Time As DateTime,AVG(p_neg) as P_Neg,AVG(p_neu) as P_Neu,AVG(p_pos) as P_Pos,AVG(p_comp) as P_Comp FROM temp GROUP BY Date_Time\")\n",
        "FinalTw_avg = FinalTw.select(\"Date_Time\",\"polarity\",\"subj\",\"p_pos\",\"p_neg\").groupBy(\"Date_Time\").agg(avg(col(\"polarity\",\"subj\",\"p_pos\",\"p_neg\")))\n",
        "FinalTw_avg.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "peaktyht5HKW",
        "outputId": "b70c4d2e-ae66-440c-f349-fd0d155d28c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------------------------------------------+\n",
            "|          Date_Time|concat_ws( , collect_list(Cleaned_Tweets))|\n",
            "+-------------------+------------------------------------------+\n",
            "|2017-11-09 14:00:00|                      hello What it fee...|\n",
            "+-------------------+------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#This cell is just to collect all the corpus per hour(for the future work)\n",
        "from pyspark.sql import functions as f\n",
        "df_with_text = FinalTw.groupby(\"Date_Time\").agg(f.concat_ws(\" \", f.collect_list(FinalTw.Cleaned_Tweets)))\n",
        "df_with_text.show(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RZ4fFp2X5HKX",
        "outputId": "5831cbec-20ec-4d90-95fb-42b9a52417c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+------------------+-------------------+-------------------+\n",
            "|           DateTime|               P_Neg|             P_Neu|              P_Pos|             P_Comp|\n",
            "+-------------------+--------------------+------------------+-------------------+-------------------+\n",
            "|2017-10-31 05:00:00|0.028692847177866968|0.8934684422959118|0.07503646569846388|0.09825245369889292|\n",
            "+-------------------+--------------------+------------------+-------------------+-------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "source": [
        "FinalTw_avg.count()\n",
        "from pyspark.sql.functions import *\n",
        "df_sort = FinalTw_avg.sort(asc(\"Date_Time\"))\n",
        "df_sort.show(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBpI0Ygg5HKX"
      },
      "source": [
        "## Joining twitter and bitcoin dataframes by DateTime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ActPdxx85HKX",
        "outputId": "64b1e355-9e71-494b-b54a-1466817329ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+------------------+-------------------+-------------------+-------+\n",
            "|           DateTime|               P_Neg|             P_Neu|              P_Pos|             P_Comp|  Price|\n",
            "+-------------------+--------------------+------------------+-------------------+-------------------+-------+\n",
            "|2017-10-31 05:00:00|0.028692847177866968|0.8934684422959118|0.07503646569846388|0.09825245369889292|6158.76|\n",
            "+-------------------+--------------------+------------------+-------------------+-------------------+-------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "source": [
        "FinalTw_avg.registerTempTable(\"avgs\")\n",
        "FinalBtc.registerTempTable(\"prices\")\n",
        "results = sql.sql(\"SELECT DateTime, P_Neg, P_Neu, P_Pos, P_Comp, Price FROM avgs JOIN prices ON avgs.DateTime = prices.Date_Time order by avgs.DateTime\")\n",
        "#results = results.selectExpr(\"DateTime\",\"avg(polarity)\",\"avg(subj)\",\"avg(p_pos)\",\"avg(p_neg)\",\"Price\") Use this line if you are using text blob package\n",
        "results.show(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Mpzd6I895HKY"
      },
      "outputs": [],
      "source": [
        "results.repartition(1).write.csv(\"DataforModelExec.csv\") #this will write df to single csv instead of writing diff csv acc to partitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0JWa7EH5HKY"
      },
      "outputs": [],
      "source": [
        "# Now refer to LSTM notebook for the timeseries analysis"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}